/**
 * TBI-J-04: Agent memory sync — generates IDE-specific config files
 * from the knowledge graph (conventions, rules, patterns, ontology).
 *
 * Supported formats:
 *   - CLAUDE.md (Claude Code)
 *   - .cursorrules (Cursor)
 *   - .github/copilot-instructions.md (GitHub Copilot)
 */

import type { IGraphStore } from "@/lib/ports/graph-store"
import type { PatternDoc, RuleDoc, DomainOntologyDoc } from "@/lib/ports/types"

export type AgentFormat = "claude" | "cursor" | "copilot"

export interface AgentMemorySyncInput {
  orgId: string
  repoId: string
  format: AgentFormat
}

export interface AgentMemorySyncResult {
  content: string
  filename: string
  format: AgentFormat
}

/**
 * Generate an IDE-specific agent configuration file from the knowledge graph.
 */
export async function generateAgentMemoryFile(
  input: AgentMemorySyncInput,
  graphStore: IGraphStore
): Promise<AgentMemorySyncResult> {
  const [patterns, rules, ontology] = await Promise.all([
    graphStore.queryPatterns(input.orgId, {
      orgId: input.orgId,
      repoId: input.repoId,
      status: "confirmed",
      limit: 100,
    }).catch((): PatternDoc[] => []),
    graphStore.queryRules(input.orgId, {
      orgId: input.orgId,
      repoId: input.repoId,
      status: "active",
      limit: 100,
    }).catch((): RuleDoc[] => []),
    graphStore.getDomainOntology(input.orgId, input.repoId).catch((): null => null),
  ])

  switch (input.format) {
    case "claude":
      return {
        content: toCLAUDEmd(patterns, rules, ontology),
        filename: "CLAUDE.md",
        format: "claude",
      }
    case "cursor":
      return {
        content: toCursorrules(patterns, rules, ontology),
        filename: ".cursorrules",
        format: "cursor",
      }
    case "copilot":
      return {
        content: toCopilotInstructions(patterns, rules, ontology),
        filename: ".github/copilot-instructions.md",
        format: "copilot",
      }
  }
}

/**
 * Claude Code CLAUDE.md format — structured markdown with imperative rules.
 */
function toCLAUDEmd(
  patterns: PatternDoc[],
  rules: RuleDoc[],
  ontology: DomainOntologyDoc | null
): string {
  const lines: string[] = []
  const projectName = ontology?.project_name ?? "Project"

  lines.push(`# ${projectName} — Agent Instructions`)
  lines.push("")
  lines.push(`> Auto-generated by unerr from detected patterns and rules.`)
  lines.push(`> Last updated: ${new Date().toISOString().split("T")[0]}`)
  lines.push("")

  // Tech stack
  if (ontology?.tech_stack && ontology.tech_stack.length > 0) {
    lines.push("## Tech Stack")
    lines.push("")
    lines.push(ontology.tech_stack.join(", "))
    lines.push("")
  }

  // Domain context
  if (ontology?.project_description) {
    lines.push("## Project Overview")
    lines.push("")
    lines.push(ontology.project_description)
    lines.push("")
  }

  // Mandatory rules (blocking)
  const blockingRules = rules.filter((r) => r.enforcement === "block")
  if (blockingRules.length > 0) {
    lines.push("## Code Rules (MUST follow)")
    lines.push("")
    for (const rule of blockingRules) {
      lines.push(`- **${rule.title}**: ${rule.description}`)
      if (rule.pathGlob) lines.push(`  Applies to: \`${rule.pathGlob}\``)
    }
    lines.push("")
  }

  // Warning rules (should follow)
  const warningRules = rules.filter((r) => r.enforcement === "warn")
  if (warningRules.length > 0) {
    lines.push("## Recommended Patterns (SHOULD follow)")
    lines.push("")
    for (const rule of warningRules) {
      lines.push(`- **${rule.title}**: ${rule.description}`)
    }
    lines.push("")
  }

  // High-confidence conventions
  const conventions = patterns.filter((p) => p.confidence > 0.7 && p.adherenceRate > 0.6)
  if (conventions.length > 0) {
    lines.push("## Detected Conventions")
    lines.push("")
    for (const p of conventions.sort((a, b) => b.adherenceRate - a.adherenceRate)) {
      const rate = Math.round(p.adherenceRate * 100)
      lines.push(`- ${p.title} (${rate}% of codebase follows this)`)
    }
    lines.push("")
  }

  // Domain language
  if (ontology?.ubiquitous_language && Object.keys(ontology.ubiquitous_language).length > 0) {
    lines.push("## Domain Language")
    lines.push("")
    const entries = Object.entries(ontology.ubiquitous_language).slice(0, 20)
    for (const [term, definition] of entries) {
      lines.push(`- **${term}**: ${definition}`)
    }
    lines.push("")
  }

  lines.push("---")
  lines.push("*Generated by [unerr](https://unerr.io)*")

  return lines.join("\n")
}

/**
 * Cursor .cursorrules format — concise, directive style.
 */
function toCursorrules(
  patterns: PatternDoc[],
  rules: RuleDoc[],
  ontology: DomainOntologyDoc | null
): string {
  const lines: string[] = []

  if (ontology?.tech_stack && ontology.tech_stack.length > 0) {
    lines.push(`# Tech Stack: ${ontology.tech_stack.join(", ")}`)
    lines.push("")
  }

  if (ontology?.project_description) {
    lines.push(`# Project: ${ontology.project_description}`)
    lines.push("")
  }

  // Mandatory rules
  const blockingRules = rules.filter((r) => r.enforcement === "block")
  if (blockingRules.length > 0) {
    lines.push("# MANDATORY RULES")
    lines.push("")
    for (const rule of blockingRules) {
      lines.push(`- ${rule.title}: ${rule.description}`)
    }
    lines.push("")
  }

  // Recommended patterns
  const warningRules = rules.filter((r) => r.enforcement === "warn")
  if (warningRules.length > 0) {
    lines.push("# RECOMMENDED PATTERNS")
    lines.push("")
    for (const rule of warningRules) {
      lines.push(`- ${rule.title}: ${rule.description}`)
    }
    lines.push("")
  }

  // High-confidence conventions
  const conventions = patterns.filter((p) => p.confidence > 0.7 && p.adherenceRate > 0.6)
  if (conventions.length > 0) {
    lines.push("# CODE CONVENTIONS")
    lines.push("")
    for (const p of conventions) {
      lines.push(`- ${p.title} (${Math.round(p.adherenceRate * 100)}% of codebase follows this)`)
    }
    lines.push("")
  }

  // Domain terms
  if (ontology?.ubiquitous_language && Object.keys(ontology.ubiquitous_language).length > 0) {
    lines.push("# DOMAIN LANGUAGE")
    lines.push("")
    const entries = Object.entries(ontology.ubiquitous_language).slice(0, 15)
    for (const [term, definition] of entries) {
      lines.push(`- ${term}: ${definition}`)
    }
    lines.push("")
  }

  return lines.join("\n")
}

/**
 * GitHub Copilot .github/copilot-instructions.md format — markdown with
 * clear sections following GitHub's recommended structure.
 */
function toCopilotInstructions(
  patterns: PatternDoc[],
  rules: RuleDoc[],
  ontology: DomainOntologyDoc | null
): string {
  const lines: string[] = []
  const projectName = ontology?.project_name ?? "Project"

  lines.push(`# Copilot Instructions for ${projectName}`)
  lines.push("")

  if (ontology?.project_description) {
    lines.push(`## About`)
    lines.push("")
    lines.push(ontology.project_description)
    lines.push("")
  }

  if (ontology?.tech_stack && ontology.tech_stack.length > 0) {
    lines.push("## Tech Stack")
    lines.push("")
    lines.push(ontology.tech_stack.join(", "))
    lines.push("")
  }

  // All rules combined
  const activeRules = rules.filter((r) => r.enforcement === "block" || r.enforcement === "warn")
  if (activeRules.length > 0) {
    lines.push("## Code Standards")
    lines.push("")
    for (const rule of activeRules) {
      const level = rule.enforcement === "block" ? "MUST" : "SHOULD"
      lines.push(`- [${level}] ${rule.title}: ${rule.description}`)
    }
    lines.push("")
  }

  // Conventions
  const conventions = patterns.filter((p) => p.confidence > 0.7 && p.adherenceRate > 0.6)
  if (conventions.length > 0) {
    lines.push("## Conventions")
    lines.push("")
    lines.push("Follow these established patterns in the codebase:")
    lines.push("")
    for (const p of conventions.sort((a, b) => b.adherenceRate - a.adherenceRate)) {
      lines.push(`- ${p.title}`)
    }
    lines.push("")
  }

  lines.push("---")
  lines.push(`*Auto-generated by [unerr](https://unerr.io) on ${new Date().toISOString().split("T")[0]}*`)

  return lines.join("\n")
}
